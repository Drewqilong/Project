{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Remove columns that missing values > 33%\n# 2. Outliers (z-score)\n# 3. Missing value \n# 4. Normalization(x-mean/(max-min))\n# 5. Relationships between columns with many 0s and target\n# 6. PCA and KPCA \n# 7. Fit model (F1 score)\n    a. Logistic regression\n    b. Random forest\n    c. SVM\n    d. Neural network\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n#df = pd.read_csv(\"equip_failures_training_set.csv\")\n#df = pd.read_csv(\"training_0.33-na-dropped.csv\")\n#df = pd.read_csv(\"training_missing-filled.csv\")\ndf = pd.read_csv(\"/kaggle/input/equipfails/equip_failures_training_set.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/equipfails/equip_failures_test_set.csv\")\ndf_join = pd.concat([df, df_test], join=\"inner\").iloc[:,1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot number of NA in columns\nWe want to see if there are too many NA in columns to decide whether we need to delete that column or not."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rates = []\nfor c in df.columns:\n    rates.append(sum(df[c].astype(str)=='na')/df[c].count())\n\n# Plot ratio of zeros in columns\nplt.figure()\nplt.plot(range(len(rates)), sorted(rates))\nplt.xlabel(\"columns\")\nplt.ylabel(\"ratio\")\nplt.title(\"Ratio of NA in Columns\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can seen from above plots, keep ratio at 33% can save most columns."},{"metadata":{},"cell_type":"markdown","source":"### Remove columns that missing values > 33%\nWe use feature-sise deletion method.\nInstead of removing rows of X (list-wise), we can remove columns of X (feature-wise)\nA general guideline would be if a feature is missing more than 33%"},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_33_na(df):\n    del_col = []\n    for c in df.columns:\n        if df[c].dtype==object and sum(df[c]=='na')/df[c].count() > 0.33:\n            del_col.append(c)\n    df = df.drop(columns = del_col)\n    return df\n\ndf_join = drop_33_na(df_join)\ndf_join.replace(\"na\", float(\"nan\"), inplace=True)\ndf_join = df_join.astype(float)\n\ndf_join.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using boxcox for normality transfromation before outliers imputation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#normality\n\n#df_join2 = df_join+1\n#from scipy.stats import boxcox\n#df_join2.loc[:,:] = boxcox(df_join, lmbda=0.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove outlier using ZScore and quantile range outlier method. \nAfter removing outlier, the F1 score is low, so we decided to keep outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_zscore_outlier(df):\n    zscore = (df - df.mean())/df.std()\n    df[zscore>3] = float(\"nan\")\n    return df\n\ndef remove_iqr_outlier(df):\n    q1, q3 = df.quantile(0.25), df.quantile(0.75)\n    iqr = q3-q1\n    l_fence, u_fence = q1 - 1.5*iqr , q3 + 1.5*iqr\n    outliers = (df<l_fence) | (df>u_fence)\n    df[outliers] = float(\"nan\")\n    return df\n\n#df_join3 = remove_zscore_outlier(df_join)\n#df_join3 = remove_iqr_outlier(df_join)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Impute missing value\nCalculate skewness for the remaining columns \nIf the skewness is between -1 and 1, then use “mean” method to impute the missing value\nIf the skewness is greater than 1 or smaller -1, then use “median”\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_missing(df):\n\n    for c in df.columns:\n        if abs(df[c].skew(skipna=True)) < 1:\n            df[c].fillna(df[c].mean(), inplace = True)\n        else:\n            df[c].fillna(df[c].median(), inplace = True)\n    return df\n\ndf_join = fill_missing(df_join)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot the ratio of zeros in columns\nWe want to see if there are too many 0 in columns to decide whether we need to delete that column or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute p(t=1, x!=0)/p(x!=0)\ntrue_pos = []\nfor c in df_join.columns:\n    col = df_join[c]\n    p11= ((df[\"target\"] == 1) &(col != 0) ).mean()\n    p_1= (col != 0 ).mean()\n    true_pos.append(p11/(p_1))\n# compute number of zeros\nrate =[]\nfor c in df_join.columns:\n    rate_0 = (df_join[c] == 0).mean()\n    rate.append(rate_0)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(range(len(rate)), sorted(rate))\nplt.title(\"Ratio of Zeros in Columns\")\nplt.xlabel(\"columns\")\nplt.ylabel(\"ratio\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring relationships between columns with many 0s and target.\nwe want to see if too many columnns with 0s have strong relationship with target, then we would remove these columns. However, from the chart above, we can see that the relationship is not strong, so we preserve these columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(rate, true_pos, '.')\nplt.title(\"Relation between Ratio of Zeros and Target\")\nplt.xlabel(\"ratio of zeros\")\nplt.ylabel(\"p(target=1, x!=0)/p(x!=0)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But we decided to keep all columnns even if it has too many 0s. The reason can be seen from the \"Relation between Ratio of Zeros and Target\" plot below."},{"metadata":{},"cell_type":"markdown","source":"### Normalizing data set using (Xi - mean(X))/ max(X) - min(X)"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_min = df_join.max()-df_join.min()\ndf_join = (df_join-df_join.mean())/max_min\ndf_join = df_join.loc[:,max_min!=0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Saving data files after cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_join.iloc[:60000]\ndf_test = df_join.iloc[60000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.to_csv(\"training_X_norm.csv\", index=False)\ndf[['id','target']].to_csv(\"training_y.csv\", index=False)\ndf_test.to_csv(\"test_X_norm.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nimport numpy as np\n\ntrain_X = pd.read_csv(\"training_X_norm.csv\")\ntrain_y = pd.read_csv(\"training_y.csv\")['target']\ntest_X = pd.read_csv(\"test_X_norm.csv\")\n\nfor i in range(10):\n    X_train, X_validate, y_train, y_validate = train_test_split(train_X, train_y)\n\n    clf = RandomForestClassifier(n_estimators=10)\n    clf.fit(X_train,y_train)\n    print(f1_score(y_validate, clf.predict(X_validate)))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score\nimport numpy as np\n\ntrain_X = pd.read_csv(\"training_X_norm.csv\")\ntrain_y = pd.read_csv(\"training_y.csv\")['target']\ntest_X = pd.read_csv(\"test_X_norm.csv\")\n\nfor i in range(0):\n    X_train, X_validate, y_train, y_validate = train_test_split(train_X, train_y)\n    rf1 = RandomForestClassifier(n_estimators=20)\n    rf2 = RandomForestClassifier(n_estimators=20)\n    svc = SVC(gamma=0.1)\n    lr  = LogisticRegression(solver=\"lbfgs\")\n\n    keep = np.random.random(len(X_train))<0.3\n    X_train_svc = X_train[keep | y_train == 1]\n    y_train_svc = y_train[keep | y_train == 1]\n\n    keep = np.random.random(len(X_train))<0.1\n    X_train_nn = X_train[keep | y_train == 1]\n    y_train_nn = y_train[keep | y_train == 1]\n    \n    rf1.fit(X_train, y_train)\n    rf2.fit(X_train, y_train)\n    svc.fit(X_train_svc, y_train_svc)\n    lr.fit(X_train, y_train)\n    #nn.fit(X_train_nn,y_train_nn)\n\n    pred_train = {}\n    pred_validate = {}\n    for i, clf in enumerate([rf1, rf2, svc, lr]):\n        pred_train[i] = clf.predict(X_train)\n        pred_validate[i] = clf.predict(X_validate)\n        \n    pred_train = pd.DataFrame(pred_train)\n    pred_validate = pd.DataFrame(pred_validate)\n    meta_rf = RandomForestClassifier(n_estimators=10)\n    meta_rf.fit(pred_train,y_train)\n    print(f1_score(y_validate, meta_rf.predict(pred_validate)))\n\nrf1 = RandomForestClassifier(n_estimators=20)\nrf2 = RandomForestClassifier(n_estimators=20)\nsvc = SVC(gamma=0.1)\nlr  = LogisticRegression(solver=\"lbfgs\")\n\nkeep = np.random.random(len(train_X))<0.3\ntrain_X_svc = train_X[keep | train_y == 1]\ntrain_y_svc = train_y[keep | train_y == 1]\n\nrf1.fit(train_X, train_y)\nrf2.fit(train_X, train_y)\nsvc.fit(train_X_svc, train_y_svc)\nlr.fit(train_X, train_y)\n\npred_train = {}\npred_test = {}\nfor i, clf in enumerate([rf1, rf2, svc, lr]):\n    pred_train[i] = clf.predict(train_X)\n    pred_test[i] = clf.predict(test_X)\n    \npred_train = pd.DataFrame(pred_train)\npred_test = pd.DataFrame(pred_test)\nmeta_rf = RandomForestClassifier(n_estimators=100)\nmeta_rf.fit(pred_train, train_y)\n#print(f1_score(y_validate, meta_rf.predict(pred_validate)))\ntest_y = meta_rf.predict(pred_test)\nprediction = pd.DataFrame({\"id\":range(1, len(test_X)+1), \"target\":test_y})\nprediction.to_csv(\"final_prediction.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}