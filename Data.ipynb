{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Remove columns that missing values > 33%\n",
    "# 2. Outliers (z-score)\n",
    "# 3. Missing value \n",
    "# 4. Normalization(x-mean/(max-min))\n",
    "# 5. Relationships between columns with many 0s and target\n",
    "# 6. PCA and KPCA \n",
    "# 7. Fit model (F1 score)\n",
    "    a. Logistic regression\n",
    "    b. Random forest\n",
    "    c. SVM\n",
    "    d. Neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#df = pd.read_csv(\"equip_failures_training_set.csv\")\n",
    "#df = pd.read_csv(\"training_0.33-na-dropped.csv\")\n",
    "#df = pd.read_csv(\"training_missing-filled.csv\")\n",
    "df = pd.read_csv(\"equip_failures_training_set.csv\")\n",
    "df_test = pd.read_csv(\"equip_failures_test_set.csv\")\n",
    "df_join = pd.concat([df, df_test], join=\"inner\").iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot number of NA in columns\n",
    "We want to see if there are too many NA in columns to decide whether we need to delete that column or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rates = []\n",
    "for c in df.columns:\n",
    "    rates.append(sum(df[c].astype(str)=='na')/df[c].count())\n",
    "\n",
    "# Plot ratio of zeros in columns\n",
    "plt.figure()\n",
    "plt.plot(range(len(rates)), sorted(rates))\n",
    "plt.xlabel(\"columns\")\n",
    "plt.ylabel(\"ratio\")\n",
    "plt.title(\"Ratio of NA in Columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can seen from above plots, keep ratio at 33% can save most columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns that missing values > 33%\n",
    "We use feature-sise deletion method.\n",
    "Instead of removing rows of X (list-wise), we can remove columns of X (feature-wise)\n",
    "A general guideline would be if a feature is missing more than 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_33_na(df):\n",
    "    del_col = []\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype==object and sum(df[c]=='na')/df[c].count() > 0.33:\n",
    "            del_col.append(c)\n",
    "    df = df.drop(columns = del_col)\n",
    "    return df\n",
    "\n",
    "df_join = drop_33_na(df_join)\n",
    "df_join.replace(\"na\", float(\"nan\"), inplace=True)\n",
    "df_join = df_join.astype(float)\n",
    "\n",
    "df_join.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using boxcox for normality transfromation before outliers imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normality\n",
    "\n",
    "#df_join2 = df_join+1\n",
    "#from scipy.stats import boxcox\n",
    "#df_join2.loc[:,:] = boxcox(df_join, lmbda=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outlier using ZScore and quantile range outlier method. \n",
    "After removing outlier, the F1 score is low, so we decided to keep outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zscore_outlier(df):\n",
    "    zscore = (df - df.mean())/df.std()\n",
    "    df[zscore>3] = float(\"nan\")\n",
    "    return df\n",
    "\n",
    "def remove_iqr_outlier(df):\n",
    "    q1, q3 = df.quantile(0.25), df.quantile(0.75)\n",
    "    iqr = q3-q1\n",
    "    l_fence, u_fence = q1 - 1.5*iqr , q3 + 1.5*iqr\n",
    "    outliers = (df<l_fence) | (df>u_fence)\n",
    "    df[outliers] = float(\"nan\")\n",
    "    return df\n",
    "\n",
    "#df_join3 = remove_zscore_outlier(df_join)\n",
    "#df_join3 = remove_iqr_outlier(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing value\n",
    "Calculate skewness for the remaining columns \n",
    "If the skewness is between -1 and 1, then use “mean” method to impute the missing value\n",
    "If the skewness is greater than 1 or smaller -1, then use “median”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(df):\n",
    "\n",
    "    for c in df.columns:\n",
    "        if abs(df[c].skew(skipna=True)) < 1:\n",
    "            df[c].fillna(df[c].mean(), inplace = True)\n",
    "        else:\n",
    "            df[c].fillna(df[c].median(), inplace = True)\n",
    "    return df\n",
    "\n",
    "df_join = fill_missing(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the ratio of zeros in columns\n",
    "We want to see if there are too many 0 in columns to decide whether we need to delete that column or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute p(t=1, x!=0)/p(x!=0)\n",
    "true_pos = []\n",
    "for c in df_join.columns:\n",
    "    col = df_join[c]\n",
    "    p11= ((df[\"target\"] == 1) &(col != 0) ).mean()\n",
    "    p_1= (col != 0 ).mean()\n",
    "    true_pos.append(p11/(p_1))\n",
    "# compute number of zeros\n",
    "rate =[]\n",
    "for c in df_join.columns:\n",
    "    rate_0 = (df_join[c] == 0).mean()\n",
    "    rate.append(rate_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(rate)), sorted(rate))\n",
    "plt.title(\"Ratio of Zeros in Columns\")\n",
    "plt.xlabel(\"columns\")\n",
    "plt.ylabel(\"ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring relationships between columns with many 0s and target.\n",
    "we want to see if too many columnns with 0s have strong relationship with target, then we would remove these columns. However, from the chart above, we can see that the relationship is not strong, so we preserve these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rate, true_pos, '.')\n",
    "plt.title(\"Relation between Ratio of Zeros and Target\")\n",
    "plt.xlabel(\"ratio of zeros\")\n",
    "plt.ylabel(\"p(target=1, x!=0)/p(x!=0)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we decided to keep all columnns even if it has too many 0s. The reason can be seen from the \"Relation between Ratio of Zeros and Target\" plot below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data set using (Xi - mean(X))/ max(X) - min(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min = df_join.max()-df_join.min()\n",
    "df_join = (df_join-df_join.mean())/max_min\n",
    "df_join = df_join.loc[:,max_min!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data files after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_join.iloc[:60000]\n",
    "df_test = df_join.iloc[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"training_X_norm.csv\", index=False)\n",
    "df[['id','target']].to_csv(\"training_y.csv\", index=False)\n",
    "df_test.to_csv(\"test_X_norm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "train_X = pd.read_csv(\"training_X_norm.csv\")\n",
    "train_y = pd.read_csv(\"training_y.csv\")['target']\n",
    "test_X = pd.read_csv(\"test_X_norm.csv\")\n",
    "\n",
    "for i in range(10):\n",
    "    X_train, X_validate, y_train, y_validate = train_test_split(train_X, train_y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=10)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(f1_score(y_validate, clf.predict(X_validate)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "train_X = pd.read_csv(\"training_X_norm.csv\")\n",
    "train_y = pd.read_csv(\"training_y.csv\")['target']\n",
    "test_X = pd.read_csv(\"test_X_norm.csv\")\n",
    "\n",
    "for i in range(0):\n",
    "    X_train, X_validate, y_train, y_validate = train_test_split(train_X, train_y)\n",
    "    rf1 = RandomForestClassifier(n_estimators=20)\n",
    "    rf2 = RandomForestClassifier(n_estimators=20)\n",
    "    svc = SVC(gamma=0.1)\n",
    "    lr  = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "    keep = np.random.random(len(X_train))<0.3\n",
    "    X_train_svc = X_train[keep | y_train == 1]\n",
    "    y_train_svc = y_train[keep | y_train == 1]\n",
    "\n",
    "    keep = np.random.random(len(X_train))<0.1\n",
    "    X_train_nn = X_train[keep | y_train == 1]\n",
    "    y_train_nn = y_train[keep | y_train == 1]\n",
    "    \n",
    "    rf1.fit(X_train, y_train)\n",
    "    rf2.fit(X_train, y_train)\n",
    "    svc.fit(X_train_svc, y_train_svc)\n",
    "    lr.fit(X_train, y_train)\n",
    "    #nn.fit(X_train_nn,y_train_nn)\n",
    "\n",
    "    pred_train = {}\n",
    "    pred_validate = {}\n",
    "    for i, clf in enumerate([rf1, rf2, svc, lr]):\n",
    "        pred_train[i] = clf.predict(X_train)\n",
    "        pred_validate[i] = clf.predict(X_validate)\n",
    "        \n",
    "    pred_train = pd.DataFrame(pred_train)\n",
    "    pred_validate = pd.DataFrame(pred_validate)\n",
    "    meta_rf = RandomForestClassifier(n_estimators=10)\n",
    "    meta_rf.fit(pred_train,y_train)\n",
    "    print(f1_score(y_validate, meta_rf.predict(pred_validate)))\n",
    "\n",
    "rf1 = RandomForestClassifier(n_estimators=20)\n",
    "rf2 = RandomForestClassifier(n_estimators=20)\n",
    "svc = SVC(gamma=0.1)\n",
    "lr  = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "keep = np.random.random(len(train_X))<0.3\n",
    "train_X_svc = train_X[keep | train_y == 1]\n",
    "train_y_svc = train_y[keep | train_y == 1]\n",
    "\n",
    "rf1.fit(train_X, train_y)\n",
    "rf2.fit(train_X, train_y)\n",
    "svc.fit(train_X_svc, train_y_svc)\n",
    "lr.fit(train_X, train_y)\n",
    "\n",
    "pred_train = {}\n",
    "pred_test = {}\n",
    "for i, clf in enumerate([rf1, rf2, svc, lr]):\n",
    "    pred_train[i] = clf.predict(train_X)\n",
    "    pred_test[i] = clf.predict(test_X)\n",
    "    \n",
    "pred_train = pd.DataFrame(pred_train)\n",
    "pred_test = pd.DataFrame(pred_test)\n",
    "meta_rf = RandomForestClassifier(n_estimators=100)\n",
    "meta_rf.fit(pred_train, train_y)\n",
    "#print(f1_score(y_validate, meta_rf.predict(pred_validate)))\n",
    "test_y = meta_rf.predict(pred_test)\n",
    "prediction = pd.DataFrame({\"id\":range(1, len(test_X)+1), \"target\":test_y})\n",
    "prediction.to_csv(\"final_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
